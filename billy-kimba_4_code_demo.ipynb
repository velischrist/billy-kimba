{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process (Erf or Linear Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model that produced our final submission. This is a relatively simple model, but it generated the best results for us. We have also worked on other models, such as SIR based models, Logistic Multiparameter models, and residual fitting models, which one can find in our github repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is simply run by the one command given at the end of this file. We decided to include some of the functions as well in this code demo because some of the function contain important parameters for the model. The model predicts all dates until the end of June. If one wants to change the prediction dates, he/she can do that in the file erf_model_small_changes, which is in the Gaussian_Processes folder. If one wants to change the training dates, he/she can simply change the boundary date of the em.fit_erf method used below inside the predict_county function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.kernel_ridge import KernelRidge as KR\n",
    "\n",
    "import pandas as pd\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir\n",
    "datadir = f\"{homedir}/Gaussian_Processes\"\n",
    "import sys\n",
    "sys.path.insert(0, datadir)\n",
    "import utils2 as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Datasetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return data ever since first min_cases cases. \n",
    "# We used this function to check if a county has always\n",
    "# had 0 deaths, in which case we predict zeroes for all deciles.\n",
    "def select_region(df, fips, min_deaths=-1):\n",
    "    d = df.loc[df['fips'] == fips]\n",
    "    deaths = np.where(d['deaths'].values > min_deaths)[0]\n",
    "    if len(deaths) == 0:\n",
    "        return []\n",
    "    start = deaths[0]\n",
    "    d = d[start:]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the processed dataset using utils helper function \n",
    "df = utils.get_processed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process with Erf prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the Gaussian Process has been done with the help of pymc3 and the tutorial links provided in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Erf model functions\n",
    "import erf_model_small_changes as em\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Erf/Linear prior as a mean function class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as tt\n",
    "\n",
    "class Erf(pm.gp.mean.Mean):\n",
    "    def __init__(self, fit_func, params):\n",
    "        self.fit_func = fit_func # Either Erf or Linear\n",
    "        self.params = params \n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = X.reshape(1, -1)[0]\n",
    "        return em.run_model(self.fit_func, self.params, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cretae function to make predictions for 1 county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_county(county_fips):\n",
    "    \n",
    "    # If the number of deaths has always been 0, \n",
    "    # simply return zeroes for all percentiles\n",
    "    d = select_region(df, county_fips)\n",
    "    if len(d) == 0:\n",
    "        return np.zeros((91, 9))\n",
    "    if np.max(d['deaths'].values) == 0:\n",
    "        return np.zeros((91, 9))\n",
    "\n",
    "    # Following is the Gaussian Process model with the Erf/Linear Prior\n",
    "    with pm.Model() as gp_covid_model:\n",
    "        # Lengthscale\n",
    "        ρ = pm.HalfCauchy('ρ', 6)\n",
    "        η = pm.HalfCauchy('η', 6)\n",
    "\n",
    "        # Fit the Erf model\n",
    "        fit_func, popt, pcov, X_train, y_train, X_pred = em.fit_erf(df, county_fips, boundary_date='2020-05-24')\n",
    "\n",
    "        # Set the Erf prior\n",
    "        M = Erf(fit_func, popt)\n",
    "        # Intialize the Covariance Function\n",
    "        K = (η**2) * pm.gp.cov.ExpQuad(1, ρ)\n",
    "        \n",
    "        # Noise of the data \n",
    "        σ = pm.HalfNormal('σ', 40)\n",
    "\n",
    "        # Compute the Marginal Likelihood of the data\n",
    "        covid_deaths_gp = pm.gp.Marginal(mean_func=M, cov_func=K)\n",
    "        covid_deaths_gp.marginal_likelihood('covid_deaths', X=X_train.reshape(-1, 1), \n",
    "                               y=y_train, noise=σ)\n",
    "\n",
    "    # Train the model using the Markov Chain Monte Carlo (MCMC) method\n",
    "    if len(popt) == 2:\n",
    "        with gp_covid_model:\n",
    "            gp_trace = pm.sample(100, tune=100, cores=2, random_seed=10)\n",
    "    else:\n",
    "        with gp_covid_model:\n",
    "            gp_trace = pm.sample(800, tune=1500, cores=2, random_seed=35)\n",
    "\n",
    "    # Make posterior predictions\n",
    "    with gp_covid_model:\n",
    "        covid_pred_noise = covid_deaths_gp.conditional(\"covid_pred_noise\", X_pred.reshape(-1,1), pred_noise=True)\n",
    "        gp_covid_samples = pm.sample_posterior_predictive(gp_trace, vars=[covid_pred_noise], samples=500, random_seed=42)\n",
    "\n",
    "    # Compute daily death count from cumulative predictions\n",
    "    all_covid_samples = np.diff(gp_covid_samples['covid_pred_noise'])\n",
    "    all_covid_samples = np.array(all_covid_samples)\n",
    "\n",
    "    # Compute the deciles for the predictions\n",
    "    all_deciles = np.transpose(np.array([np.percentile(all_covid_samples, per, axis=0) for per in np.arange(10, 100, 10)]))\n",
    "    all_deciles[all_deciles < 0] = 0\n",
    "    \n",
    "    return all_deciles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to make the final predictions for all counties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_counties(out_file):\n",
    "    out_dates = utils.all_output_dates()\n",
    "    out_fips, all_row_starts = utils.all_output_fips('sample_submission.csv')\n",
    "    num_dates, num_fips = len(out_dates), len(out_fips)\n",
    "    out = np.zeros((num_dates * num_fips, 9))\n",
    "    # Go through each county one by one, perform our fit, and record predictions\n",
    "    for fi, fips in enumerate(out_fips):\n",
    "        print('Processing FIPS', fips)\n",
    "        preds = predict_county(float(fips))\n",
    "        # Indices are disjointed because we're recording a single FIPS on many different dates\n",
    "        out[np.arange(fi, out.shape[0], num_fips)] = preds\n",
    "    # Add in the header line\n",
    "    out_lines = [','.join(['id'] + ['%d' % x for x in np.arange(10, 91, 10)]) + '\\n']\n",
    "    # Add in all other lines one at a time\n",
    "    for row_head, row in zip(all_row_starts, out):\n",
    "        out_lines.append(','.join([row_head] + ['%.2f' % val for val in row]) + '\\n')\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.writelines(out_lines)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been finalized. To produce the submission file, one simply needs to run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 10001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 4 divergences: 100%|██████████| 4600/4600 [00:30<00:00, 148.56draws/s]\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "100%|██████████| 500/500 [00:05<00:00, 92.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 10003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 0 divergences: 100%|██████████| 4600/4600 [00:25<00:00, 178.54draws/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 93.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 10005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 5 divergences: 100%|██████████| 4600/4600 [00:48<00:00, 95.50draws/s] \n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6428342269228152, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 500/500 [00:07<00:00, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 0 divergences: 100%|██████████| 400/400 [00:02<00:00, 146.64draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9177289136562271, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9004037481219446, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 101.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 2 divergences: 100%|██████████| 400/400 [00:03<00:00, 122.18draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8907692910359618, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9151547997990539, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "100%|██████████| 500/500 [00:04<00:00, 109.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 165 divergences: 100%|██████████| 400/400 [00:02<00:00, 142.35draws/s]\n",
      "There were 64 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.49349111079823066, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 107.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 165 divergences: 100%|██████████| 400/400 [00:02<00:00, 141.44draws/s]\n",
      "There were 64 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.49349111079823066, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 101.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 165 divergences: 100%|██████████| 400/400 [00:02<00:00, 172.00draws/s]\n",
      "There were 64 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.49349111079823066, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 101.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 165 divergences: 100%|██████████| 400/400 [00:03<00:00, 121.38draws/s]\n",
      "There were 64 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.49349111079823066, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 115.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 0 divergences: 100%|██████████| 4600/4600 [00:39<00:00, 117.56draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 110.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 200 divergences: 100%|██████████| 400/400 [00:02<00:00, 164.13draws/s]\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.5896913218667597, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.1513000928280537, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:05<00:00, 90.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 0 divergences: 100%|██████████| 4600/4600 [00:28<00:00, 159.84draws/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 106.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 1 divergences: 100%|██████████| 400/400 [00:01<00:00, 205.01draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9480888519286992, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9066906348036741, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "100%|██████████| 500/500 [00:05<00:00, 90.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 165 divergences: 100%|██████████| 400/400 [00:02<00:00, 143.73draws/s]\n",
      "There were 64 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.49349111079823066, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:05<00:00, 95.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 1 divergences: 100%|██████████| 400/400 [00:02<00:00, 152.75draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9579414655034245, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9268493922796245, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "100%|██████████| 500/500 [00:05<00:00, 97.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 200 divergences: 100%|██████████| 400/400 [00:05<00:00, 71.85draws/s] \n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.6105094887389774, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain contains only diverging samples. The model is probably misspecified.\n",
      "The acceptance probability does not match the target. It is 0.5838064932235352, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 112.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 101 divergences:  75%|███████▌  | 301/400 [00:03<00:01, 90.79draws/s]\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "100%|██████████| 500/500 [00:04<00:00, 110.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIPS 1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [σ, η, ρ]\n",
      "Sampling 2 chains, 0 divergences:  11%|█▏        | 45/400 [00:00<00:01, 181.63draws/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_msg_pipe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-36e660da1491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_all_counties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-80f612274388>\u001b[0m in \u001b[0;36mpredict_all_counties\u001b[0;34m(out_file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfips\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_fips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing FIPS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_county\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Indices are disjointed because we're recording a single FIPS on many different dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63fa9d3eb219>\u001b[0m in \u001b[0;36mpredict_county\u001b[0;34m(county_fips)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgp_covid_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mgp_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgp_covid_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough samples to build a trace.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "predict_all_counties('final_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime: This model takes about 8 hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
